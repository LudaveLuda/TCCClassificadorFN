{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a00175cc",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%run ./Coletar_Dados.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "53b629f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset, target, classes = RetornarDatasets('./output/preprocessed/basetcc/true.csv', './output/preprocessed/basetcc/fake.csv')\n",
    "datasetBr, targetBr, classesBr = RetornarDatasets('./output/preprocessed/fakebr/true.csv', './output/preprocessed/fakebr/fake.csv')\n",
    "datasetNorm, targetNorm, classesNorm = RetornarDatasets('./output/preprocessed/normfakebr/true.csv', './output/preprocessed/normfakebr/fake.csv')\n",
    "datasetTrun, targetTrun, classesTrun = RetornarDatasets('./output/preprocessed/normtcc/true.csv', './output/preprocessed/normtcc/fake.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c216f70",
   "metadata": {},
   "source": [
    "### Gerando word embeddings\n",
    "\n",
    "Transformar o texto em um vetor de atributos com valores numéricos. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "459a3ab5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Primeira mensagem de texto\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "embeddings = []\n",
    "for row in dataset:\n",
    "    embeddings.append(row[1].split())\n",
    "    \n",
    "for row in datasetBr:\n",
    "    embeddings.append(row[1].split())\n",
    "    \n",
    "print('Primeira mensagem de texto')\n",
    "print(embeddings[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10953223",
   "metadata": {},
   "source": [
    "Importanto pacotes dos métodos de embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "694bea92",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "from gensim.test.utils import common_texts\n",
    "from gensim.models import Word2Vec\n",
    "from gensim.models import FastText\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f6d51c8",
   "metadata": {},
   "source": [
    "Treinando o modelo de embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0364b14a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model2Vec = Word2Vec(sentences=embeddings, vector_size=200, window=3, min_count=2, workers=4)\n",
    "modelFast = FastText(vector_size=200, window=3, min_count=2, sentences=embeddings, epochs=10)\n",
    "\n",
    "vocab2VecSize = len(model2Vec.wv)\n",
    "vocabFastSize = len(modelFast.wv)\n",
    "print('Tamanho do vocabulário do modelo Word2Vec: ', vocab2VecSize)\n",
    "print('Tamanho do vocabulário do modelo FastText: ', vocabFastSize)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b8ff17d",
   "metadata": {},
   "source": [
    "Avaliando os termos mais próximos de um determinado termo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fbe6d7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sims = model2Vec.wv.most_similar('vacin')\n",
    "for sim in sims:\n",
    "    print(sim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5452e656",
   "metadata": {},
   "outputs": [],
   "source": [
    "sims = modelFast.wv.most_similar('vacin')\n",
    "for sim in sims:\n",
    "    print(sim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "34bcb832",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getDocvector(model, doc): \n",
    "    \"\"\"\n",
    "    obtem o vetor de cada palavra de um documento e calcula um vetor medio\n",
    "    \"\"\"\n",
    "    \n",
    "    vectorList = []\n",
    "    for word in doc:\n",
    "        try:\n",
    "            vectorList.append( model.wv[word] )\n",
    "        except:\n",
    "            pass # essa termo do python significa que não há nada a fazer\n",
    "            \n",
    "    # se a lista de vetores for vazia retorna zero, senao retorna a media dos vetores\n",
    "    if len(vectorList)>0:\n",
    "        vetorMedio  = np.mean(vectorList, axis=0)\n",
    "    else:\n",
    "        vetorMedio = np.zeros( model.wv.vector_size )\n",
    "        \n",
    "    \n",
    "    return vetorMedio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b01bca3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset2Vec = []\n",
    "dataset2VecBr = []\n",
    "dataset2VecNorm = []\n",
    "dataset2VecTrun = []\n",
    "datasetFast = []\n",
    "datasetFastBr = []\n",
    "datasetFastNorm = []\n",
    "datasetFastTrun = []\n",
    "datasetBow = []\n",
    "datasetBowBr = []\n",
    "datasetBowNorm = []\n",
    "datasetBowTrun = []\n",
    "docList = []\n",
    "\n",
    "matrix = CountVectorizer(max_features=1000)\n",
    "\n",
    "for row in dataset:\n",
    "    dataset2Vec.append(getDocvector(model2Vec, row[1].split()))\n",
    "    datasetFast.append(getDocvector(modelFast, row[1].split()))\n",
    "    \n",
    "    docList.append(row[1])\n",
    "    \n",
    "for row in datasetBr:\n",
    "    dataset2VecBr.append(getDocvector(model2Vec, row[1].split()))\n",
    "    datasetFastBr.append(getDocvector(modelFast, row[1].split()))\n",
    "    \n",
    "    docList.append(row[1])\n",
    "    \n",
    "for row in datasetNorm:\n",
    "    dataset2VecNorm.append(getDocvector(model2Vec, row[1].split()))\n",
    "    datasetFastNorm.append(getDocvector(modelFast, row[1].split()))\n",
    "    \n",
    "    docList.append(row[1])\n",
    "    \n",
    "for row in datasetTrun:\n",
    "    dataset2VecTrun.append(getDocvector(model2Vec, row[1].split()))\n",
    "    datasetFastTrun.append(getDocvector(modelFast, row[1].split()))\n",
    "    \n",
    "    docList.append(row[1])\n",
    "    \n",
    "dataset2Vec = np.array(dataset2Vec, dtype=object)\n",
    "dataset2VecBr = np.array(dataset2VecBr, dtype=object)\n",
    "dataset2VecNorm = np.array(dataset2VecNorm, dtype=object)\n",
    "dataset2VecTrun = np.array(dataset2VecTrun, dtype=object)\n",
    "datasetFast = np.array(datasetFast, dtype=object)\n",
    "datasetFastBr = np.array(datasetFastBr, dtype=object)\n",
    "datasetFastNorm = np.array(datasetFastNorm, dtype=object)\n",
    "datasetFastTrun = np.array(datasetFastTrun, dtype=object)\n",
    "\n",
    "listBow = np.array(matrix.fit_transform(docList).toarray(), dtype=object)\n",
    "datasetBow = listBow[:3260]\n",
    "datasetBowBr = listBow[3260:10460]\n",
    "datasetBowNorm = listBow[10460:17660]\n",
    "datasetBowTrun = listBow[17660:]\n",
    "\n",
    "print(\"Dimensao de dataset2Vec: \", dataset2Vec.shape)\n",
    "print(\"Dimensao de dataset2VecBr\", dataset2VecBr.shape)\n",
    "print(\"Dimensao de dataset2VecNorm\", dataset2VecNorm.shape)\n",
    "print(\"Dimensao de dataset2VecTrun\", dataset2VecTrun.shape)\n",
    "print(\"Dimensao de datasetFast: \", datasetFast.shape)\n",
    "print(\"Dimensao de datasetFastBr\", datasetFastBr.shape)\n",
    "print(\"Dimensao de datasetFastNorm\", datasetFastNorm.shape)\n",
    "print(\"Dimensao de datasetFastTrun\", datasetFastTrun.shape)\n",
    "print(\"Dimensao de datasetBow: \", datasetBow.shape)\n",
    "print(\"Dimensao de datasetBowBr\", datasetBowBr.shape)\n",
    "print(\"Dimensao de datasetBowNorm\", datasetBowNorm.shape)\n",
    "print(\"Dimensao de datasetBowTrun\", datasetBowTrun.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b7b617d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2596d788",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasetFast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8790aa63",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasetBow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bf9d114",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
