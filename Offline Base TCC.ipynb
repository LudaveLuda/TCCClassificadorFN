{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2ec8c897",
   "metadata": {},
   "source": [
    "Bora lá, vamos tentar filtrar notícias verdadeiras e notícias falsas\n",
    "\n",
    "Primeiro, precisamos improtar todas as bibliotecas que serão usadas ao longo deste notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5a145d26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bibliotecas carregadas com sucesso\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "import numpy as np # biblioteca usada para trabalhar com vetores e matrizes\n",
    "import pandas as pd # biblioteca usada para trabalhar com dataframes e análise de dados\n",
    "import sklearn as skl # sckit-learn\n",
    "import time # biblioteca usada para calcular o tempo de execucao\n",
    "import re # biblioteca para expressoes regulares\n",
    "import os # biblioteca usada para realizar tarefas específicas ao SO\n",
    "\n",
    "\n",
    "# importa alguns pacotes do sckit-learn\n",
    "from sklearn import model_selection \n",
    "from sklearn import naive_bayes # necessario para usar o metodo naive Bayes\n",
    "from sklearn import model_selection # necessario para fazer validacao cruzada\n",
    "from sklearn import metrics # necessario para obter o desempenho da classificacao\n",
    "\n",
    "import nltk # biblioteca para Processamento de Linguagem Natural\n",
    "from nltk.stem.porter import PorterStemmer # para fazer a estemização em documentos da lingua inglesa\n",
    "from nltk.stem import RSLPStemmer # para fazer a estemização em documentos da lingua portuguesa\n",
    "\n",
    "import unicodedata # sera usada para remover acentos dos documentos em lingua portuguesa\n",
    "\n",
    "# bibliotecas para geração de gráficos\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# biblioteca para tratar com caminho de arquivo\n",
    "from pathlib import Path\n",
    "\n",
    "# biblioteca para leitura de csv\n",
    "import csv\n",
    "\n",
    "print('Bibliotecas carregadas com sucesso')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0164118a",
   "metadata": {},
   "source": [
    "Separando o download de todos os recursos da biblioteca NLTK, que esse demora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cdb2036",
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.download('all')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e8b5a0e",
   "metadata": {},
   "source": [
    "Separando dados entre dados e treino"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9e57edae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ImportDatasetToArray(pathDataset):\n",
    "    dataset = []\n",
    "    target = []\n",
    "    \n",
    "    with open(pathDataset, newline='', encoding='utf-8-sig') as csvfile:\n",
    "        reader = csv.reader(csvfile, delimiter=';')\n",
    "        next(reader, None)\n",
    "        \n",
    "        classification = Path(pathDataset).stem\n",
    "        \n",
    "        for row in reader:\n",
    "            dataset.append(row)\n",
    "            target.append(classification)\n",
    "            \n",
    "    return dataset, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "543a478f",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasetTrue = []\n",
    "targetTrue = []\n",
    "datasetTrue, targetTrue = ImportDatasetToArray('./input/data/true.csv')\n",
    "\n",
    "datasetFake = []\n",
    "targetFake = []\n",
    "datasetFake, targetFake = ImportDatasetToArray('./input/data/fake.csv')\n",
    "\n",
    "dataset = np.asarray(datasetTrue + datasetFake)\n",
    "target = np.asarray(targetTrue + targetFake)\n",
    "classes = np.unique(target)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ebcb32a",
   "metadata": {},
   "source": [
    "Separando dados entre dados de treino e teste (Pesquisar divisão de treino por meio de cruzada K-fold, supostamente é mais robusta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c3fe0bad",
   "metadata": {},
   "outputs": [],
   "source": [
    "porcentagemTreino = 0.8\n",
    "seed = 20\n",
    "permutedIndexes = np.random.RandomState(seed).permutation(dataset.shape[0])\n",
    "\n",
    "datasetShuffled, targetShuffled = dataset[permutedIndexes], target[permutedIndexes]\n",
    "\n",
    "qtdTreino = int(datasetShuffled.shape[0]*porcentagemTreino)\n",
    "setTreino, targetTreino = datasetShuffled[0:qtdTreino], targetShuffled[0:qtdTreino]\n",
    "setTeste, targetTeste = datasetShuffled[qtdTreino:], targetShuffled[qtdTreino:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a9f15475",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Qtd. dados de treinamento: 2608 (80.00%)\n",
      "Qtd. de dados de teste: 652 (20.00%)\n",
      "Proporção classes treino: 50.42%/49.58% (true/fake)\n",
      "Proporção classes testes: 48.31%/51.69% (true/fake)\n"
     ]
    }
   ],
   "source": [
    "print('Qtd. dados de treinamento: %d (%1.2f%%)' %(setTreino.shape[0], (setTreino.shape[0]/dataset.shape[0])*100))\n",
    "print('Qtd. de dados de teste: %d (%1.2f%%)' %(setTeste.shape[0], (setTeste.shape[0]/dataset.shape[0])*100))\n",
    "print('Proporção classes treino: %1.2f%%/%1.2f%% (true/fake)' %((targetTreino[targetTreino == 'true'].shape[0]/targetTreino.shape[0]) * 100, (targetTreino[targetTreino == 'fake'].shape[0]/targetTreino.shape[0])*100))\n",
    "print('Proporção classes testes: %1.2f%%/%1.2f%% (true/fake)' %((targetTeste[targetTeste == 'true'].shape[0]/targetTeste.shape[0])*100, (targetTeste[targetTeste == 'fake'].shape[0]/targetTeste.shape[0]) * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "517f11f9",
   "metadata": {},
   "source": [
    "Realizando pré-processamento das amostras\n",
    "\n",
    "Pré-processamentos realizados:\n",
    "  - Deixar todas as palavras com letras minúsculas\n",
    "  - Substituir os números pela tag *\\<NUMBER\\>*\n",
    "  - Substituir as URLS pela tag *\\<URL\\>*\n",
    "  - Substituir os emails pela tag *\\<EMAIL\\>*\n",
    "  - Substituir os símbolos de moeda pela tag *\\<MONEY\\>*\n",
    "  - Substituir todos os caracteres não-alfanuméricos por um espaço em branco\n",
    "  - Removido stopwords\n",
    "  - Aplicado estemização\n",
    "  - Removido palavras com apenas um caracter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c43965a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(text, stemming = False, stopwords = False):\n",
    "    \"\"\"\n",
    "    Funcao usada para fazer o tratamento de textos da lingua portuguesa\n",
    "    \n",
    "    Parametros: \n",
    "        text: variavel do tipo string que contem o texto que devera ser tratado\n",
    "        \n",
    "        stemming: variavel do tipo booleana que indica se a estemizacao deve ser aplicada ou nao\n",
    "        \n",
    "        stopwords: variavel do tipo booleana que indica se as stopwords devem ser removidas ou nao\n",
    "    \"\"\"\n",
    "    \n",
    "    # Lower case\n",
    "    text = text.lower()\n",
    "    \n",
    "    # remove tags HTML\n",
    "    regex = re.compile('<[^<>]+>')\n",
    "    text = re.sub(regex, \" \", text) \n",
    "    \n",
    "    # normaliza as URLs\n",
    "    regex = re.compile('(http|https)://[^\\s]*')\n",
    "    text = re.sub(regex, \"<URL>\", text)\n",
    "\n",
    "    # normaliza emails\n",
    "    regex = re.compile('[^\\s]+@[^\\s]+')\n",
    "    text = re.sub(regex, \"<EMAIL>\", text)\n",
    "\n",
    "    #normaliza o símbolo de dólar\n",
    "    regex = re.compile('[$]+')\n",
    "    text = re.sub(regex, \"<MONEY>\", text)    \n",
    "    \n",
    "    # converte todos os caracteres não-alfanuméricos em espaço\n",
    "    regex = re.compile('[^A-Za-z0-9]+')  \n",
    "    text = re.sub(regex, \" \", text)\n",
    "    \n",
    "    # normaliza os numeros \n",
    "    regex = re.compile('[0-9]+')\n",
    "    text = re.sub(regex, \"<NUMBER>\", text)\n",
    "    \n",
    "    # substitui varios espaçamentos seguidos em um só\n",
    "    text = ' '.join(text.split())\n",
    "\n",
    "    # remove stopwords\n",
    "    if stopwords:\n",
    "        words = text.split() # separa o texto em palavras\n",
    "        words = [w for w in words if not w in nltk.corpus.stopwords.words('portuguese')]\n",
    "        text = \" \".join( words )\n",
    "    \n",
    "    # aplica estemização\n",
    "    if stemming: \n",
    "        stemmer_method = RSLPStemmer()  \n",
    "        words = text.split() # separa o texto em palavras\n",
    "        words = [ stemmer_method.stem(w) for w in words ]\n",
    "        text = \" \".join( words )\n",
    "    \n",
    "    # remove palavras de apenas um caracter\n",
    "    words = text.split() # separa o texto em palavras\n",
    "    words = [ w for w in words if len(w)>1 ]\n",
    "    text = \" \".join( words )\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2593c82c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 652 de 65208\r"
     ]
    }
   ],
   "source": [
    "for i, msg in enumerate(setTreino):\n",
    "    setTreino[i][1] = preprocessing(setTreino[i][1], stemming = True, stopwords = True)\n",
    "    \n",
    "    if i%50==0 or i==len(setTreino)-1:\n",
    "        print(' %d de %d' %(i+1, len(setTreino)), end='\\r')\n",
    "        \n",
    "for i, msg in enumerate(setTeste):\n",
    "    setTeste[i][1] = preprocessing(setTeste[i][1], stemming = True, stopwords = True)\n",
    "    \n",
    "    if i%50==0 or i==len(setTeste)-1:\n",
    "        print(' %d de %d' %(i+1, len(setTeste)), end='\\r')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "661b855b",
   "metadata": {},
   "source": [
    "### Gerando word embeddings\n",
    "\n",
    "Transformar o texto em um vetor de atributos com valores numéricos. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fab7712",
   "metadata": {},
   "outputs": [],
   "source": [
    "msgTreinoEmb = []\n",
    "for row in setTreino:\n",
    "    msgTreinoEmb.append(row[1].split())\n",
    "    \n",
    "print('Primeira mensagem de texto')\n",
    "print(msgTreinoEmb[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65644b39",
   "metadata": {},
   "source": [
    "Treinando o modelo de embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9c55662",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "from gensim.test.utils import common_texts\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "model = Word2Vec(sentences=msgTreinoEmb, vector_size=200, window=3, min_count=2, workers=4)\n",
    "\n",
    "vocabSize = len(model.wv)\n",
    "print('Tamanho do vocabulário do modelo: ', vocabSize)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d37483b",
   "metadata": {},
   "source": [
    "Avaliando os temor mais próximos de um determinado termo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69434130",
   "metadata": {},
   "outputs": [],
   "source": [
    "sims = model.wv.most_similar('vacin')\n",
    "for sim in sims:\n",
    "    print(sim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b3d96a41",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getDocvector(model, doc): \n",
    "    \"\"\"\n",
    "    obtem o vetor de cada palavra de um documento e calcula um vetor medio\n",
    "    \"\"\"\n",
    "    \n",
    "    vectorList = []\n",
    "    for word in doc:\n",
    "        try:\n",
    "            vectorList.append( model.wv[word] )\n",
    "        except:\n",
    "            pass # essa termo do python significa que não há nada a fazer\n",
    "            \n",
    "    # se a lista de vetores for vazia retorna zero, senao retorna a media dos vetores\n",
    "    if len(vectorList)>0:\n",
    "        vetorMedio  = np.mean(vectorList, axis=0)\n",
    "    else:\n",
    "        vetorMedio = np.zeros( model.wv.vector_size )\n",
    "        \n",
    "    \n",
    "    return vetorMedio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08a9daf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "targetTreino"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb72c60a",
   "metadata": {},
   "outputs": [],
   "source": [
    "rowTreinoEmb = []\n",
    "for row in setTreino:\n",
    "    rowTreinoEmb.append([ getDocvector(model, row[1].split()), row[2], row[3], row[4]])\n",
    "    \n",
    "rowTesteEmb = []\n",
    "for row in setTeste:\n",
    "    rowTesteEmb.append([ getDocvector(model, row[1].split()), row[2], row[3], row[4]])\n",
    "    \n",
    "rowTreinoEmb = np.array(rowTreinoEmb, dtype=object)\n",
    "rowTesteEmb = np.array(rowTesteEmb, dtype=object)\n",
    "\n",
    "print(\"Dimensao de rowTreinoEmb: \", rowTreinoEmb.shape)\n",
    "print(\"Dimensao de rowTesteEmb: \", rowTesteEmb.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d37a18df",
   "metadata": {},
   "outputs": [],
   "source": [
    "rowTreinoEmb = []\n",
    "for row in setTreino:\n",
    "    rowTreinoEmb.append(getDocvector(model, row[1].split()))\n",
    "    \n",
    "rowTesteEmb = []\n",
    "for row in setTeste:\n",
    "    rowTesteEmb.append(getDocvector(model, row[1].split()))\n",
    "    \n",
    "rowTreinoEmb = np.array(rowTreinoEmb, dtype=object)\n",
    "rowTesteEmb = np.array(rowTesteEmb, dtype=object)\n",
    "\n",
    "print(\"Dimensao de rowTreinoEmb: \", rowTreinoEmb.shape)\n",
    "print(\"Dimensao de rowTesteEmb: \", rowTesteEmb.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26772129",
   "metadata": {},
   "outputs": [],
   "source": [
    "rowTreinoEmb = []\n",
    "for row in setTreino:\n",
    "    rowTreinoEmb.append(np.concatenate((getDocvector(model, row[1].split()), np.array([(int(row[2])-16)/15, (int(row[3])-6.5)/5.5, (int(row[4]) - 2020.5)/0.5], dtype='float32'))))\n",
    "    \n",
    "rowTesteEmb = []\n",
    "for row in setTeste:\n",
    "    rowTesteEmb.append(np.concatenate((getDocvector(model, row[1].split()), np.array([(int(row[2])-16)/15, (int(row[3])-6.5)/5.5, (int(row[4]) - 2020.5)/0.5], dtype='float32'))))\n",
    "    \n",
    "rowTreinoEmb = np.array(rowTreinoEmb, dtype=object)\n",
    "rowTesteEmb = np.array(rowTesteEmb, dtype=object)\n",
    "\n",
    "print(\"Dimensao de rowTreinoEmb: \", rowTreinoEmb.shape)\n",
    "print(\"Dimensao de rowTesteEmb: \", rowTesteEmb.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bf09051",
   "metadata": {},
   "outputs": [],
   "source": [
    "rowTreinoEmb = []\n",
    "for row in setTreino:\n",
    "    rowTreinoEmb.append(np.concatenate((getDocvector(model, row[1].split()), np.array([(int(row[2])-1)/30, (int(row[3])-1)/11, int(row[4]) - 2020], dtype='float32'))))\n",
    "    \n",
    "rowTesteEmb = []\n",
    "for row in setTeste:\n",
    "    rowTesteEmb.append(np.concatenate((getDocvector(model, row[1].split()), np.array([(int(row[2])-1)/30, (int(row[3])-1)/11, int(row[4]) - 2020], dtype='float32'))))\n",
    "    \n",
    "rowTreinoEmb = np.array(rowTreinoEmb, dtype=object)\n",
    "rowTesteEmb = np.array(rowTesteEmb, dtype=object)\n",
    "\n",
    "print(\"Dimensao de rowTreinoEmb: \", rowTreinoEmb.shape)\n",
    "print(\"Dimensao de rowTesteEmb: \", rowTesteEmb.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24653008",
   "metadata": {},
   "source": [
    "Utilizando método Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6775ef41",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "from sklearn.linear_model import Perceptron\n",
    "\n",
    "# criando um novo perceptron\n",
    "perceptron = Perceptron(random_state=0, max_iter=30)\n",
    "\n",
    "# treina o classificador com os dados de treinameto\n",
    "perceptron.fit(rowTreinoEmb, targetTreino) \n",
    " \n",
    "# classifica os dados de teste\n",
    "predicao = perceptron.predict(rowTesteEmb) \n",
    "        \n",
    "print('\\nPredição obtida para as 20 primeiras amostras de teste:\\n', predicao[0:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be4cb3cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "resultados = sklearn.metrics.classification_report(targetTeste, predicao, target_names=classes)\n",
    "\n",
    "print(resultados)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a6a5eda",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
