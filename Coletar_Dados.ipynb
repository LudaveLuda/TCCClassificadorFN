{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1de26e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "import numpy as np # biblioteca usada para trabalhar com vetores e matrizes\n",
    "import pandas as pd # biblioteca usada para trabalhar com dataframes e análise de dados\n",
    "import sklearn as skl # sckit-learn\n",
    "import time # biblioteca usada para calcular o tempo de execucao\n",
    "import re # biblioteca para expressoes regulares\n",
    "import os # biblioteca usada para realizar tarefas específicas ao SO\n",
    "\n",
    "\n",
    "# importa alguns pacotes do sckit-learn\n",
    "from sklearn import model_selection \n",
    "from sklearn import naive_bayes # necessario para usar o metodo naive Bayes\n",
    "from sklearn import model_selection # necessario para fazer validacao cruzada\n",
    "from sklearn import metrics # necessario para obter o desempenho da classificacao\n",
    "\n",
    "import nltk # biblioteca para Processamento de Linguagem Natural\n",
    "from nltk.stem.porter import PorterStemmer # para fazer a estemização em documentos da lingua inglesa\n",
    "from nltk.stem import RSLPStemmer # para fazer a estemização em documentos da lingua portuguesa\n",
    "\n",
    "import unicodedata # sera usada para remover acentos dos documentos em lingua portuguesa\n",
    "\n",
    "# bibliotecas para geração de gráficos\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# biblioteca para tratar com caminho de arquivo\n",
    "from pathlib import Path\n",
    "\n",
    "# biblioteca para leitura de csv\n",
    "import csv\n",
    "\n",
    "print('Bibliotecas carregadas com sucesso')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04036ff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.download('all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b25927fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ImportDatasetToArray(pathDataset):\n",
    "    dataset = []\n",
    "    target = []\n",
    "    \n",
    "    with open(pathDataset, newline='', encoding='utf-8-sig') as csvfile:\n",
    "        reader = csv.reader(csvfile, delimiter=';')\n",
    "        next(reader, None)\n",
    "        \n",
    "        classification = Path(pathDataset).stem\n",
    "        \n",
    "        for row in reader:\n",
    "            dataset.append(row)\n",
    "            target.append(classification)\n",
    "            \n",
    "    return dataset, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9ceed9d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def RetornarDatasets(pathToTrue, pathToFake):\n",
    "    datasetTrue = []\n",
    "    targetTrue = []\n",
    "    datasetTrue, targetTrue = ImportDatasetToArray(pathToTrue)\n",
    "\n",
    "    datasetFake = []\n",
    "    targetFake = []\n",
    "    datasetFake, targetFake = ImportDatasetToArray(pathToFake)\n",
    "\n",
    "    dataset = np.asarray(datasetTrue + datasetFake)\n",
    "    target = np.asarray(targetTrue + targetFake)\n",
    "    classes = np.unique(target)\n",
    "    \n",
    "    ind = np.lexsort((dataset[:,4], dataset[:,3], dataset[:,2], dataset[:,1]))\n",
    "    \n",
    "    return dataset[ind], target[ind], classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcbe7813",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
